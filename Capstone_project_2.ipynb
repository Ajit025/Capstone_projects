{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3678e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6035ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "positive    25000\n",
      "negative    25000\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('IMDB Dataset.csv.zip')\n",
    "print(data)\n",
    "print(data.head())\n",
    "print(data['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99f7d4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the data\n",
    "X = data['review']\n",
    "y = data['sentiment'].replace({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Build a model\n",
    "clf = SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, random_state=42, max_iter=1000, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "806dfb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8823\n",
      "Accuracy: 0.8823\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {acc:.4f}')\n",
    "\n",
    "# Make an end-to-end model\n",
    "model = Pipeline([('vectorizer', CountVectorizer()), ('clf', SGDClassifier(random_state=42))])\n",
    "model.fit(X_train, y_train)\n",
    "acc = model.score(X_test, y_test)\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8855afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data['review']\n",
    "y = data['sentiment'].replace({'positive': 1, 'negative': 0})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "895367f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vect, y_train)\n",
    "accuracy = model.score(X_test_vect, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5c2cd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36244054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0]\n",
      "Prediction: [1]\n"
     ]
    }
   ],
   "source": [
    "new_review_1 = \"This movie was terrible.\"\n",
    "new_review_2 =\"This movie was amazing\"\n",
    "prediction_1 = pipeline.predict([new_review_1])\n",
    "prediction_2= pipeline.predict([new_review_2])\n",
    "\n",
    "print(\"Prediction:\", prediction_1)\n",
    "print(\"Prediction:\", prediction_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27b6134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=100)\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb4de919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling2D, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=16, input_length=100),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2e460da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.4718 - accuracy: 0.7916 - val_loss: 0.4687 - val_accuracy: 0.7922\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4706 - accuracy: 0.7921 - val_loss: 0.4674 - val_accuracy: 0.7938\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.4693 - accuracy: 0.7936 - val_loss: 0.4662 - val_accuracy: 0.7950\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4681 - accuracy: 0.7930 - val_loss: 0.4652 - val_accuracy: 0.7962\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4668 - accuracy: 0.7942 - val_loss: 0.4638 - val_accuracy: 0.7950\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4656 - accuracy: 0.7949 - val_loss: 0.4627 - val_accuracy: 0.7966\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.4644 - accuracy: 0.7959 - val_loss: 0.4615 - val_accuracy: 0.7958\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4632 - accuracy: 0.7963 - val_loss: 0.4603 - val_accuracy: 0.7962\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4621 - accuracy: 0.7968 - val_loss: 0.4591 - val_accuracy: 0.7981\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4609 - accuracy: 0.7976 - val_loss: 0.4580 - val_accuracy: 0.7990\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4598 - accuracy: 0.7982 - val_loss: 0.4570 - val_accuracy: 0.7987\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4586 - accuracy: 0.7990 - val_loss: 0.4557 - val_accuracy: 0.7988\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4575 - accuracy: 0.7994 - val_loss: 0.4548 - val_accuracy: 0.8012\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4564 - accuracy: 0.8001 - val_loss: 0.4536 - val_accuracy: 0.8011\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4553 - accuracy: 0.8001 - val_loss: 0.4527 - val_accuracy: 0.8019\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4542 - accuracy: 0.8018 - val_loss: 0.4515 - val_accuracy: 0.8022\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4531 - accuracy: 0.8016 - val_loss: 0.4505 - val_accuracy: 0.8019\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4521 - accuracy: 0.8022 - val_loss: 0.4493 - val_accuracy: 0.8031\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4510 - accuracy: 0.8033 - val_loss: 0.4485 - val_accuracy: 0.8038\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4500 - accuracy: 0.8031 - val_loss: 0.4473 - val_accuracy: 0.8049\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4490 - accuracy: 0.8037 - val_loss: 0.4463 - val_accuracy: 0.8047\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.4480 - accuracy: 0.8041 - val_loss: 0.4453 - val_accuracy: 0.8048\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4469 - accuracy: 0.8052 - val_loss: 0.4444 - val_accuracy: 0.8059\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4459 - accuracy: 0.8054 - val_loss: 0.4435 - val_accuracy: 0.8066\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4449 - accuracy: 0.8063 - val_loss: 0.4423 - val_accuracy: 0.8054\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4439 - accuracy: 0.8063 - val_loss: 0.4413 - val_accuracy: 0.8062\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4430 - accuracy: 0.8065 - val_loss: 0.4404 - val_accuracy: 0.8063\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4421 - accuracy: 0.8074 - val_loss: 0.4395 - val_accuracy: 0.8077\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.4411 - accuracy: 0.8082 - val_loss: 0.4386 - val_accuracy: 0.8063\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4401 - accuracy: 0.8083 - val_loss: 0.4376 - val_accuracy: 0.8081\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4392 - accuracy: 0.8088 - val_loss: 0.4367 - val_accuracy: 0.8094\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4383 - accuracy: 0.8088 - val_loss: 0.4358 - val_accuracy: 0.8093\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4374 - accuracy: 0.8094 - val_loss: 0.4350 - val_accuracy: 0.8099\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4365 - accuracy: 0.8101 - val_loss: 0.4341 - val_accuracy: 0.8094\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.4356 - accuracy: 0.8105 - val_loss: 0.4331 - val_accuracy: 0.8112\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4347 - accuracy: 0.8106 - val_loss: 0.4323 - val_accuracy: 0.8123\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4338 - accuracy: 0.8117 - val_loss: 0.4315 - val_accuracy: 0.8118\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4329 - accuracy: 0.8115 - val_loss: 0.4306 - val_accuracy: 0.8142\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4321 - accuracy: 0.8127 - val_loss: 0.4298 - val_accuracy: 0.8147\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4312 - accuracy: 0.8131 - val_loss: 0.4291 - val_accuracy: 0.8146\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4304 - accuracy: 0.8131 - val_loss: 0.4281 - val_accuracy: 0.8133\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4295 - accuracy: 0.8132 - val_loss: 0.4273 - val_accuracy: 0.8141\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4287 - accuracy: 0.8141 - val_loss: 0.4266 - val_accuracy: 0.8136\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4279 - accuracy: 0.8146 - val_loss: 0.4257 - val_accuracy: 0.8152\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4271 - accuracy: 0.8148 - val_loss: 0.4249 - val_accuracy: 0.8149\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4262 - accuracy: 0.8154 - val_loss: 0.4241 - val_accuracy: 0.8158\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4254 - accuracy: 0.8154 - val_loss: 0.4233 - val_accuracy: 0.8156\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4246 - accuracy: 0.8164 - val_loss: 0.4227 - val_accuracy: 0.8147\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4239 - accuracy: 0.8165 - val_loss: 0.4218 - val_accuracy: 0.8159\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4231 - accuracy: 0.8169 - val_loss: 0.4211 - val_accuracy: 0.8146\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4223 - accuracy: 0.8171 - val_loss: 0.4204 - val_accuracy: 0.8155\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4215 - accuracy: 0.8177 - val_loss: 0.4196 - val_accuracy: 0.8163\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4208 - accuracy: 0.8178 - val_loss: 0.4188 - val_accuracy: 0.8174\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4200 - accuracy: 0.8183 - val_loss: 0.4183 - val_accuracy: 0.8183\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4193 - accuracy: 0.8185 - val_loss: 0.4174 - val_accuracy: 0.8164\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4185 - accuracy: 0.8190 - val_loss: 0.4171 - val_accuracy: 0.8183\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4178 - accuracy: 0.8193 - val_loss: 0.4160 - val_accuracy: 0.8162\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4170 - accuracy: 0.8195 - val_loss: 0.4153 - val_accuracy: 0.8200\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4164 - accuracy: 0.8200 - val_loss: 0.4146 - val_accuracy: 0.8175\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4156 - accuracy: 0.8202 - val_loss: 0.4139 - val_accuracy: 0.8201\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4149 - accuracy: 0.8205 - val_loss: 0.4135 - val_accuracy: 0.8191\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.4143 - accuracy: 0.8210 - val_loss: 0.4126 - val_accuracy: 0.8204\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4135 - accuracy: 0.8211 - val_loss: 0.4119 - val_accuracy: 0.8203\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4128 - accuracy: 0.8216 - val_loss: 0.4112 - val_accuracy: 0.8214\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.4121 - accuracy: 0.8220 - val_loss: 0.4107 - val_accuracy: 0.8202\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4114 - accuracy: 0.8220 - val_loss: 0.4099 - val_accuracy: 0.8206\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4108 - accuracy: 0.8218 - val_loss: 0.4092 - val_accuracy: 0.8217\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4101 - accuracy: 0.8228 - val_loss: 0.4086 - val_accuracy: 0.8222\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4095 - accuracy: 0.8228 - val_loss: 0.4079 - val_accuracy: 0.8227\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4088 - accuracy: 0.8237 - val_loss: 0.4074 - val_accuracy: 0.8238\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4081 - accuracy: 0.8239 - val_loss: 0.4067 - val_accuracy: 0.8223\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.4075 - accuracy: 0.8240 - val_loss: 0.4062 - val_accuracy: 0.8229\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4068 - accuracy: 0.8245 - val_loss: 0.4055 - val_accuracy: 0.8227\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4061 - accuracy: 0.8245 - val_loss: 0.4050 - val_accuracy: 0.8247\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4055 - accuracy: 0.8252 - val_loss: 0.4044 - val_accuracy: 0.8247\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4049 - accuracy: 0.8250 - val_loss: 0.4036 - val_accuracy: 0.8252\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4043 - accuracy: 0.8256 - val_loss: 0.4031 - val_accuracy: 0.8245\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4036 - accuracy: 0.8256 - val_loss: 0.4027 - val_accuracy: 0.8259\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4030 - accuracy: 0.8258 - val_loss: 0.4020 - val_accuracy: 0.8269\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.4024 - accuracy: 0.8262 - val_loss: 0.4013 - val_accuracy: 0.8256\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4017 - accuracy: 0.8266 - val_loss: 0.4008 - val_accuracy: 0.8251\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4012 - accuracy: 0.8266 - val_loss: 0.4001 - val_accuracy: 0.8272\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4005 - accuracy: 0.8267 - val_loss: 0.3998 - val_accuracy: 0.8253\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.4000 - accuracy: 0.8273 - val_loss: 0.3991 - val_accuracy: 0.8280\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3993 - accuracy: 0.8281 - val_loss: 0.3984 - val_accuracy: 0.8268\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.3988 - accuracy: 0.8280 - val_loss: 0.3980 - val_accuracy: 0.8283\n",
      "Epoch 87/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.3982 - accuracy: 0.8285 - val_loss: 0.3975 - val_accuracy: 0.8293\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3976 - accuracy: 0.8284 - val_loss: 0.3968 - val_accuracy: 0.8286\n",
      "Epoch 89/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3971 - accuracy: 0.8286 - val_loss: 0.3963 - val_accuracy: 0.8283\n",
      "Epoch 90/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3964 - accuracy: 0.8291 - val_loss: 0.3957 - val_accuracy: 0.8272\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.3958 - accuracy: 0.8288 - val_loss: 0.3954 - val_accuracy: 0.8264\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.3953 - accuracy: 0.8293 - val_loss: 0.3947 - val_accuracy: 0.8279\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3947 - accuracy: 0.8298 - val_loss: 0.3942 - val_accuracy: 0.8285\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3942 - accuracy: 0.8300 - val_loss: 0.3936 - val_accuracy: 0.8275\n",
      "Epoch 95/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.3936 - accuracy: 0.8297 - val_loss: 0.3932 - val_accuracy: 0.8277\n",
      "Epoch 96/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3931 - accuracy: 0.8305 - val_loss: 0.3926 - val_accuracy: 0.8298\n",
      "Epoch 97/100\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.3925 - accuracy: 0.8308 - val_loss: 0.3921 - val_accuracy: 0.8294\n",
      "Epoch 98/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3920 - accuracy: 0.8307 - val_loss: 0.3917 - val_accuracy: 0.8294\n",
      "Epoch 99/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3915 - accuracy: 0.8309 - val_loss: 0.3912 - val_accuracy: 0.8312\n",
      "Epoch 100/100\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3909 - accuracy: 0.8309 - val_loss: 0.3906 - val_accuracy: 0.8304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20da9e473a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_padded, y_train, epochs=100, batch_size=32, validation_data=(X_test_padded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0cb9c31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8304\n",
      "Loss: 0.39055612683296204\n",
      "Accuracy: 0.8303999900817871\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "129d48ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Prediction: negative\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(review):\n",
    "    review_seq = tokenizer.texts_to_sequences([review])\n",
    "    review_padded = pad_sequences(review_seq, maxlen=100)\n",
    "    prediction = model.predict(review_padded)[0][0]\n",
    "    if prediction >= 0.5:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "new_review = \"This movie was terrible. The acting was bad and the plot was boring.\"\n",
    "prediction = predict_sentiment(new_review)\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b7222e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702549d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
